{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59f5aff1",
   "metadata": {},
   "source": [
    "# Presentazione esperimento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01712b90",
   "metadata": {},
   "source": [
    "**Panoramica**\n",
    "Secondo step sull'easy set: arricchisce la pipeline dati e aggiorna l'engine per sfruttare metadati aggiuntivi pur rispondendo solo alle domande Easy.\n",
    "\n",
    "**Pipeline dati**\n",
    "- Ingestione identica al baseline ma con classificazione (`classify_menu`) per assegnare metadati di contesto.\n",
    "- Estrazione in due step: prima normalizzazione e tagging tramite classificazione/aggregazione, poi `extract_info_from_menus` costruisce record strutturati.\n",
    "- Mapping unificato `create_mappings` che centralizza ingredienti, tecniche e riferimenti testuali.\n",
    "\n",
    "**Evoluzione dell'engine**\n",
    "- Passaggio a `engine_medium`, ereditando i tool Easy e aggiungendo pianeti (`get_planet_dish_ids`), ristoranti (`get_restaurant_dish_ids`) e licenze (`get_chef_licence_dish_ids`).\n",
    "- Introduzione di `union_dish_ids` per gestire query additive oltre a intersect/subtract.\n",
    "- Valutazione con `evaluate_easy_questions` per confrontare direttamente il nuovo toolset sulle stesse domande.\n",
    "\n",
    "**Ruolo nel percorso**\n",
    "Serve per quantificare quanto le informazioni extra e il toolset medium migliorino le risposte Easy prima di passare alle domande Medium.\n",
    "\n",
    "**Performance (Jaccard)**: 100%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa90010",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "\t\n",
    "cwd = Path.cwd().resolve()\n",
    "project_dir = cwd.parent.parent\n",
    "\n",
    "if str(project_dir) not in sys.path:\n",
    "\tsys.path.insert(0, str(project_dir))\n",
    "\t\n",
    "\n",
    "dataset_file_path = project_dir / \"Dataset\"\n",
    "artifacts_file_path = cwd / \"artifacts\"\n",
    "\n",
    "if not os.path.exists(artifacts_file_path):\n",
    "        os.makedirs(artifacts_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8530b4bd",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98621a25",
   "metadata": {},
   "source": [
    "## Parsing e aggregazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f305a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.menu_ingestion import group_and_concatenate_documents, parse_documents_in_directory\n",
    "from src.utils import write_json\n",
    "\n",
    "\n",
    "menus_path = dataset_file_path / \"Knowledge_base\" / \"menu\"\n",
    "documents_pages = parse_documents_in_directory(document_path=menus_path)\n",
    "documents = group_and_concatenate_documents(documents=documents_pages)\n",
    "write_json(documents, artifacts_file_path / \"parsed_menus.json\")\n",
    "\n",
    "for doc_name, doc_text in list(documents.items())[:5]:\n",
    "    print(f\"Document: {doc_name}\\nContent Preview: {doc_text[:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea06443",
   "metadata": {},
   "source": [
    "## Classificazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10a4c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.menu_classification import classify_menu\n",
    "\n",
    "classifications = classify_menu(text_extracted=documents, model_name=\"gpt-4.1\")\n",
    "write_json(classifications, artifacts_file_path / \"menu_classifications.json\")\n",
    "\n",
    "for doc_name, classification in list(classifications.items())[:5]:\n",
    "    print(f\"Document: {doc_name}\\nClassification: {classification}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d7a5ea",
   "metadata": {},
   "source": [
    "## Estrazione strutturata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50bc080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.menu_extraction import extract_info_from_menus\n",
    "\n",
    "extracted_info = extract_info_from_menus(documents=documents, classifications=classifications, model_name=\"gpt-4.1\")\n",
    "write_json(extracted_info, artifacts_file_path / \"extracted_menu_info.json\")\n",
    "\n",
    "for info in extracted_info[:5]:\n",
    "    restaurant_name = info.get(\"restaurant_name\", \"Unknown\")\n",
    "    print(f\"Document: {restaurant_name}\\nExtracted Info: {info}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03b23fd",
   "metadata": {},
   "source": [
    "## Creazione di mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a2af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.menu_mapping import create_mappings_technique_ingredient\n",
    "from src.utils import read_json\n",
    "\n",
    "dish_mapping = read_json(dataset_file_path / \"ground_truth\" / \"dish_mapping.json\")\n",
    "ingredient_to_dishes, technique_to_dishes = create_mappings_technique_ingredient(extracted_info=extracted_info, dish_mapping=dish_mapping)\n",
    "\n",
    "write_json(technique_to_dishes, artifacts_file_path / 'technique_to_dishes.json')\n",
    "write_json(ingredient_to_dishes, artifacts_file_path / 'ingredient_to_dishes.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b38aa4e",
   "metadata": {},
   "source": [
    "# Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9689c74",
   "metadata": {},
   "source": [
    "## Agente conversazionale / interrogazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36468e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ai.agents.engine_easy import get_agent, query_dish_ids\n",
    "\n",
    "agent = get_agent(model_name=\"grok-4-1-fast-reasoning\")\n",
    "response = query_dish_ids(question=\"Quali sono i piatti che includono le Chocobo Wings come ingrediente?\", agent=agent)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e83cec",
   "metadata": {},
   "source": [
    "## Valutazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b839afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.questions_evaluation import evaluate_questions\n",
    "\n",
    "\n",
    "question_path = dataset_file_path / \"domande.csv\"\n",
    "ground_truth_path = dataset_file_path / \"ground_truth\" / \"ground_truth_mapped.csv\"\n",
    "eval_df = evaluate_questions(agent=agent, question_path=question_path, ground_truth_path=ground_truth_path, level=\"easy\")\n",
    "eval_df.to_csv(artifacts_file_path / \"easy_questions_evaluation_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80afaced",
   "metadata": {},
   "outputs": [],
   "source": [
    "score =  round(eval_df['score'].mean()*100, 2)\n",
    "print(f\"Accuracy: {score}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fcf7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
