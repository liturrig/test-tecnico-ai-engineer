{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8026fa2",
   "metadata": {},
   "source": [
    "# Presentazione esperimento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9623341",
   "metadata": {},
   "source": [
    "**Panoramica**\n",
    "Integra Manuale di Cucina, Codice Galattico e distanze planetarie per coprire anche le domande Hard mantenendo compatibilita con le richieste piu semplici.\n",
    "\n",
    "**Pipeline dati**\n",
    "- Mantiene parsing/classificazione/mapping dei menu per retro-compatibilita.\n",
    "- Aggiunge ingestion ed estrazione (`extraction_call`) su Manuale e Codice per ricavare categorie tecniche, requisiti di licenza e limiti normativi.\n",
    "- Calcola mapping incrociati (licenze->tecniche, tecniche->piatti) e utilizza `Distanze.csv` per ragionare sulle distanze.\n",
    "\n",
    "**Evoluzione dell'engine**\n",
    "- `engine_hard` arricchisce ulteriormente il toolset con `get_technique_from_category`, `get_dish_from_minimum_licence`, `get_dishes_with_both_technique_categories` e `get_dishes_within_distance`.\n",
    "- I tool Medium restano disponibili, consentendo sia filtri geospaziali sia controlli su licenze minime e combinazioni di categorie.\n",
    "- Le set-ops finali rifiniscono i risultati dopo catene di ragionamento multi-fonte.\n",
    "\n",
    "**Ruolo nel percorso**\n",
    "Costituisce l'implementazione piu completa prima del livello Impossible, dimostrando come le diverse fonti vengano orchestrate nello stesso agente.\n",
    "\n",
    "**Performance (Jaccard)**: 99.31%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62974fb4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0717eebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "\t\n",
    "cwd = Path.cwd().resolve()\n",
    "project_dir = cwd.parent.parent\n",
    "\n",
    "if str(project_dir) not in sys.path:\n",
    "\tsys.path.insert(0, str(project_dir))\n",
    "\t\n",
    "\n",
    "dataset_file_path = project_dir / \"Dataset\"\n",
    "artifacts_file_path = cwd / \"artifacts\"\n",
    "\n",
    "if not os.path.exists(artifacts_file_path):\n",
    "        os.makedirs(artifacts_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf23e5e8",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc3e792",
   "metadata": {},
   "source": [
    "## Menu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0784e6",
   "metadata": {},
   "source": [
    "### Parsing e aggregazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a2c560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.menu_ingestion import group_and_concatenate_documents, parse_documents_in_directory\n",
    "from src.utils import write_json\n",
    "\n",
    "\n",
    "menus_path = dataset_file_path / \"Knowledge_base\" / \"menu\"\n",
    "documents_pages = parse_documents_in_directory(document_path=[menus_path])\n",
    "documents = group_and_concatenate_documents(documents=documents_pages)\n",
    "write_json(documents, artifacts_file_path / \"parsed_menus.json\")\n",
    "\n",
    "for doc_name, doc_text in list(documents.items())[:5]:\n",
    "    print(f\"Document: {doc_name}\\nContent Preview: {doc_text[:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0c3f60",
   "metadata": {},
   "source": [
    "### Classificazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a32721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.menu_classification import classify_menu\n",
    "\n",
    "classifications = classify_menu(text_extracted=documents, model_name=\"grok-4-1-fast-reasoning\")\n",
    "write_json(classifications, artifacts_file_path / \"menu_classifications.json\")\n",
    "\n",
    "for doc_name, classification in list(classifications.items())[:5]:\n",
    "    print(f\"Document: {doc_name}\\nClassification: {classification}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74be4bd4",
   "metadata": {},
   "source": [
    "### Estrazione struttura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fec0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.menu_extraction import extract_info_from_menus\n",
    "from src.utils import read_json, write_json\n",
    "\n",
    "documents = read_json(artifacts_file_path / \"parsed_menus.json\")\n",
    "classifications = read_json(artifacts_file_path / \"menu_classifications.json\")\n",
    "\n",
    "extracted_info = extract_info_from_menus(documents=documents, classifications=classifications, model_name=\"grok-4-1-fast-reasoning\")\n",
    "write_json(extracted_info, artifacts_file_path / \"extracted_menu_info.json\")\n",
    "\n",
    "for info in extracted_info[:5]:\n",
    "    restaurant_name = info.get(\"restaurant_name\", \"Unknown\")\n",
    "    print(f\"Document: {restaurant_name}\\nExtracted Info: {info}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdbae3f",
   "metadata": {},
   "source": [
    "### Creazione di mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea7494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.menu_mapping import create_mappings_planets_restaurant_skills\n",
    "from src.utils import read_json,write_json\n",
    "\n",
    "dish_mapping = read_json(dataset_file_path / \"ground_truth\" / \"dish_mapping.json\")\n",
    "\n",
    "planet_to_dishes, restaurant_to_dishes, skill_to_dishes = create_mappings_planets_restaurant_skills(extracted_info=extracted_info, dish_mapping=dish_mapping)\n",
    "\n",
    "write_json(planet_to_dishes, artifacts_file_path / 'planet_to_dishes.json')\n",
    "write_json(restaurant_to_dishes, artifacts_file_path / 'restaurant_to_dishes.json')\n",
    "write_json(skill_to_dishes, artifacts_file_path / 'skill_to_dishes.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3cab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.menu_mapping import create_mappings_technique_ingredient\n",
    "\n",
    "ingredient_to_dishes, technique_to_dishes = create_mappings_technique_ingredient(extracted_info=extracted_info, dish_mapping=dish_mapping)\n",
    "write_json(ingredient_to_dishes, artifacts_file_path / 'ingredient_to_dishes.json')\n",
    "write_json(technique_to_dishes, artifacts_file_path / 'technique_to_dishes.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428767fc",
   "metadata": {},
   "source": [
    "## Manuale di Cucina"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c7fdf0",
   "metadata": {},
   "source": [
    "### Parsing e aggregazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fe9fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.menu_ingestion import group_and_concatenate_documents, parse_documents_in_directory\n",
    "from src.utils import write_json\n",
    "\n",
    "\n",
    "menus_path = dataset_file_path / \"Knowledge_base\" / \"misc\" / \"Manuale di Cucina.pdf\"\n",
    "documents_pages = parse_documents_in_directory(file_path=[menus_path])\n",
    "documents = group_and_concatenate_documents(documents=documents_pages)\n",
    "write_json(documents, artifacts_file_path / \"parsed_manuale_di_cucina.json\")\n",
    "\n",
    "for doc_name, doc_text in list(documents.items())[:5]:\n",
    "    print(f\"Document: {doc_name}\\nContent Preview: {doc_text[:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77259ff",
   "metadata": {},
   "source": [
    "### Estrazione strutturata e mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c291d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ai.agents.extractor import extraction_call\n",
    "from src.ai.models.manuale_extractor import ResultExtracted\n",
    "from src.ai.prompts.manuale_extractor import INPUT_PROMPT, SYSTEM_PROMPT\n",
    "from src.preprocessing.manuale_mapping import mapping_category_technique\n",
    "\n",
    "text = documents[\"Manuale di Cucina.pdf\"]\n",
    "\n",
    "category_techniques = extraction_call(text=text, \n",
    "                                      model_name=\"gpt-4.1\", \n",
    "                                      system_prompt=SYSTEM_PROMPT, \n",
    "                                      input_prompt=INPUT_PROMPT, \n",
    "                                      output_cls=ResultExtracted)\n",
    "\n",
    "category_techniques_mapped = mapping_category_technique(category_techniques)\n",
    "\n",
    "write_json(category_techniques_mapped, artifacts_file_path / \"category_to_techniques.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58527a4f",
   "metadata": {},
   "source": [
    "## Codice galattico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d6b33e",
   "metadata": {},
   "source": [
    "### Parsing e aggregazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d969a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.menu_ingestion import group_and_concatenate_documents, parse_documents_in_directory\n",
    "from src.utils import write_json\n",
    "\n",
    "\n",
    "menus_path = dataset_file_path / \"Knowledge_base\" / \"codice_galattico\" / \"Codice Galattico.pdf\"\n",
    "documents_pages = parse_documents_in_directory(file_path=[menus_path])\n",
    "documents = group_and_concatenate_documents(documents=documents_pages)\n",
    "write_json(documents, artifacts_file_path / \"parsed_manuale_di_cucina.json\")\n",
    "\n",
    "for doc_name, doc_text in list(documents.items())[:5]:\n",
    "    print(f\"Document: {doc_name}\\nContent Preview: {doc_text[:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa75767",
   "metadata": {},
   "source": [
    "### Estrazione strutturata e mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec16c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ai.agents.extractor import extraction_call\n",
    "from src.ai.models.codice_extractor import ResultExtracted\n",
    "from src.ai.prompts.codice_extractor import INPUT_PROMPT, SYSTEM_PROMPT\n",
    "from src.preprocessing.codice_mapping import mapping_licences\n",
    "\n",
    "text = documents[\"Codice Galattico.pdf\"]\n",
    "\n",
    "licence_to_techniques = extraction_call(text=text,\n",
    "                                        model_name=\"gpt-4.1\",\n",
    "                                        system_prompt=SYSTEM_PROMPT,\n",
    "                                        input_prompt=INPUT_PROMPT,\n",
    "                                        output_cls=ResultExtracted)\n",
    "\n",
    "licence_to_techniques_dict = mapping_licences(licence_to_techniques)\n",
    "\n",
    "write_json(licence_to_techniques_dict, artifacts_file_path / \"licence_to_techniques.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d953f7b7",
   "metadata": {},
   "source": [
    "# Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf982178",
   "metadata": {},
   "source": [
    "## Agente conversazionale / interrogazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296e91fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ai.prompts.hard_engine import SYSTEM_PROMPT\n",
    "\n",
    "categories_str = \"\\n- \".join(list(category_techniques_mapped.keys()))\n",
    "system_prompt = SYSTEM_PROMPT.format(categories=categories_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdfb811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ai.agents.engine_hard import get_agent, query_dish_ids\n",
    "\n",
    "agent = get_agent(model_name=\"grok-4-1-fast-reasoning\",system_prompt=system_prompt)\n",
    "response = query_dish_ids(question=\"Quali piatti sono stati creati utilizzando almeno una tecnica di SURGELAMENTO secondo il Manuale di Cucina di Sirius Cosmo e sono stati serviti in un ristorante situato entro un raggio di 317 anni luce dal pianeta Krypton, Krypton incluso?\", agent=agent)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f91d5d",
   "metadata": {},
   "source": [
    "## Valutazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fdb43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.questions_evaluation import evaluate_questions\n",
    "\n",
    "question_path = dataset_file_path / \"domande.csv\"\n",
    "ground_truth_path = dataset_file_path / \"ground_truth\" / \"ground_truth_mapped.csv\"\n",
    "eval_df = evaluate_questions(agent=agent, question_path=question_path, ground_truth_path=ground_truth_path, level=\"all\")\n",
    "eval_df.to_csv(artifacts_file_path / \"hard_questions_evaluation_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d6c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "score =  round(eval_df['score'].mean()*100, 2)\n",
    "print(f\"Accuracy: {score}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4785a38b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
